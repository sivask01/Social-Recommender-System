{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "828553f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1621463 entries, 0 to 1621462\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count    Dtype  \n",
      "---  ------         --------------    -----  \n",
      " 0   work           1621463 non-null  int64  \n",
      " 1   user           1621463 non-null  object \n",
      " 2   stars          1357973 non-null  float64\n",
      " 3   time           1621463 non-null  object \n",
      " 4   clean_comment  1621463 non-null  object \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 61.9+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filter_df = pd.read_csv('short_clean_comments_df.csv')\n",
    "filter_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd711e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/anaconda3/lib/python3.11/site-packages (from langdetect) (1.16.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=759708b821876da8910a7fd18934992844ecc6d96add005529d27dd966520ab9\n",
      "  Stored in directory: /Users/admin/Library/Caches/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12e32ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language\n",
      "en         1483589\n",
      "nl           24592\n",
      "fr           21394\n",
      "es           19216\n",
      "it           15075\n",
      "de           11633\n",
      "da            6098\n",
      "sv            5758\n",
      "af            5257\n",
      "no            4145\n",
      "ca            4042\n",
      "pt            3991\n",
      "fi            2982\n",
      "ro            1703\n",
      "cy            1484\n",
      "tl            1255\n",
      "pl            1159\n",
      "so            1155\n",
      "id            1055\n",
      "sl             987\n",
      "et             874\n",
      "sk             866\n",
      "hu             603\n",
      "lt             543\n",
      "cs             475\n",
      "tr             360\n",
      "hr             350\n",
      "sw             281\n",
      "sq             260\n",
      "lv             164\n",
      "vi             115\n",
      "unknown          2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "filter_df['language'] = filter_df['clean_comment'].apply(detect_language)\n",
    "language_counts = filter_df['language'].value_counts()\n",
    "print(language_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dce620d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1575499 entries, 0 to 1621462\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count    Dtype  \n",
      "---  ------         --------------    -----  \n",
      " 0   work           1575499 non-null  int64  \n",
      " 1   user           1575499 non-null  object \n",
      " 2   stars          1325457 non-null  float64\n",
      " 3   time           1575499 non-null  object \n",
      " 4   clean_comment  1575499 non-null  object \n",
      " 5   language       1575499 non-null  object \n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 84.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work</th>\n",
       "      <th>user</th>\n",
       "      <th>stars</th>\n",
       "      <th>time</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73960</td>\n",
       "      <td>Elizabeth.Wong98</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Mar 21, 2012</td>\n",
       "      <td>every evening the brave queen of persia shahra...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69413</td>\n",
       "      <td>rivkat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sep 20, 2009</td>\n",
       "      <td>its the  school year and edward zanni of hobok...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9523995</td>\n",
       "      <td>suz.haugland</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Mar 12, 2011</td>\n",
       "      <td>i became privy to this book when another autho...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11243828</td>\n",
       "      <td>CandyH</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Feb 12, 2012</td>\n",
       "      <td>this is a tremendous story of a freed woman an...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9071901</td>\n",
       "      <td>miyurose</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Jul 12, 2010</td>\n",
       "      <td>and with this book i am officially caught up w...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621458</th>\n",
       "      <td>11633344</td>\n",
       "      <td>TheLogo</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Aug 25, 2011</td>\n",
       "      <td>i came to this book with low expectations the ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621459</th>\n",
       "      <td>129503</td>\n",
       "      <td>evementen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jan 29, 2012</td>\n",
       "      <td>this is quite possibly the cutest kids book iv...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621460</th>\n",
       "      <td>11749693</td>\n",
       "      <td>AmyMacEvilly</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mar 31, 2013</td>\n",
       "      <td>this is a fairy tale which is very much a cupi...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621461</th>\n",
       "      <td>9705446</td>\n",
       "      <td>bibliosa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nov 22, 2011</td>\n",
       "      <td>despus del extraordinario xito de los ojos ama...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621462</th>\n",
       "      <td>32396</td>\n",
       "      <td>jlelliott</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Aug 31, 2007</td>\n",
       "      <td>i originally met most of the diseases covered ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1575499 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             work              user  stars          time  \\\n",
       "0           73960  Elizabeth.Wong98    4.5  Mar 21, 2012   \n",
       "1           69413            rivkat    3.0  Sep 20, 2009   \n",
       "2         9523995      suz.haugland    4.0  Mar 12, 2011   \n",
       "3        11243828            CandyH    4.0  Feb 12, 2012   \n",
       "4         9071901          miyurose    2.0  Jul 12, 2010   \n",
       "...           ...               ...    ...           ...   \n",
       "1621458  11633344           TheLogo    4.5  Aug 25, 2011   \n",
       "1621459    129503         evementen    NaN  Jan 29, 2012   \n",
       "1621460  11749693      AmyMacEvilly    5.0  Mar 31, 2013   \n",
       "1621461   9705446          bibliosa    NaN  Nov 22, 2011   \n",
       "1621462     32396         jlelliott    4.0  Aug 31, 2007   \n",
       "\n",
       "                                             clean_comment language  \n",
       "0        every evening the brave queen of persia shahra...       en  \n",
       "1        its the  school year and edward zanni of hobok...       en  \n",
       "2        i became privy to this book when another autho...       en  \n",
       "3        this is a tremendous story of a freed woman an...       en  \n",
       "4        and with this book i am officially caught up w...       en  \n",
       "...                                                    ...      ...  \n",
       "1621458  i came to this book with low expectations the ...       en  \n",
       "1621459  this is quite possibly the cutest kids book iv...       en  \n",
       "1621460  this is a fairy tale which is very much a cupi...       en  \n",
       "1621461  despus del extraordinario xito de los ojos ama...       es  \n",
       "1621462  i originally met most of the diseases covered ...       en  \n",
       "\n",
       "[1575499 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the top 6 languages by frequency\n",
    "top_6_languages = filter_df['language'].value_counts().head(6).index.tolist()\n",
    "\n",
    "# Filter rows corresponding to the top 6 languages\n",
    "filtered_df = filter_df[filter_df['language'].isin(top_6_languages)]\n",
    "\n",
    "# Select only the relevant columns (if needed)\n",
    "#selected_columns = ['clean_comment', 'language']  # Adjust this list based on the columns you need\n",
    "#filtered_df = filtered_df[selected_columns]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "filtered_df.info()\n",
    "\n",
    "# Save the filtered DataFrame to a CSV file (optional)\n",
    "filtered_df.to_csv('filtered_top_6_languages.csv', index=False)\n",
    "\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcccaec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1575499 entries, 0 to 1575498\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count    Dtype  \n",
      "---  ------         --------------    -----  \n",
      " 0   work           1575499 non-null  int64  \n",
      " 1   user           1575499 non-null  object \n",
      " 2   stars          1325457 non-null  float64\n",
      " 3   time           1575499 non-null  object \n",
      " 4   clean_comment  1575499 non-null  object \n",
      " 5   language       1575499 non-null  object \n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 72.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "work              456159\n",
       "user               78623\n",
       "stars                 10\n",
       "time                2920\n",
       "clean_comment    1538680\n",
       "language               6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_csv('filtered_top_6_languages.csv')\n",
    "df_all.info()\n",
    "\n",
    "df_all.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "665f2c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "en    1483589\n",
       "nl      24592\n",
       "fr      21394\n",
       "es      19216\n",
       "it      15075\n",
       "de      11633\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "364ff474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame shape: (1575499, 6)\n",
      "Cleaned DataFrame shape: (1538680, 6)\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate rows based on 'clean_comment' column\n",
    "df_cleaned = df_all.drop_duplicates(subset='clean_comment', keep='first')\n",
    "\n",
    "# Display the shape of the cleaned DataFrame to confirm changes\n",
    "print(f\"Original DataFrame shape: {df_all.shape}\")\n",
    "print(f\"Cleaned DataFrame shape: {df_cleaned.shape}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file_path = \"full_cleaned.csv\"\n",
    "df_cleaned.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ffb227e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1538680 entries, 0 to 1538679\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count    Dtype  \n",
      "---  ------         --------------    -----  \n",
      " 0   work           1538680 non-null  int64  \n",
      " 1   user           1538680 non-null  object \n",
      " 2   stars          1298896 non-null  float64\n",
      " 3   time           1538680 non-null  object \n",
      " 4   clean_comment  1538680 non-null  object \n",
      " 5   language       1538680 non-null  object \n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 70.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "work              446821\n",
       "user               78055\n",
       "stars                 10\n",
       "time                2920\n",
       "clean_comment    1538680\n",
       "language               6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_csv('full_cleaned.csv')\n",
    "df_all.info()\n",
    "\n",
    "df_all.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081ffeca",
   "metadata": {},
   "source": [
    "## Sentiment analysis with textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4d123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import time\n",
    "\n",
    "# Sentiment Analysis with 5 Scores\n",
    "def get_sentiment_label_and_score(text):\n",
    "    analysis = TextBlob(text)\n",
    "    polarity = analysis.sentiment.polarity  # Actual polarity value (-1 to 1)\n",
    "\n",
    "    # Define sentiment categories\n",
    "    if polarity > 0.6:\n",
    "        sentiment_label, sentiment_score = \"Extremely Positive\", 5.0\n",
    "    elif polarity > 0:\n",
    "        sentiment_label, sentiment_score = \"Positive\", 4.0\n",
    "    elif polarity == 0:\n",
    "        sentiment_label, sentiment_score = \"Neutral\", 3.0\n",
    "    elif polarity > -0.6:\n",
    "        sentiment_label, sentiment_score = \"Negative\", 2.0\n",
    "    else:\n",
    "        sentiment_label, sentiment_score = \"Extremely Negative\", 1.0\n",
    "\n",
    "    return sentiment_label, sentiment_score, (polarity + 1)/2\n",
    "\n",
    "start_time = time.time()\n",
    "df_all[['sentiment_label_textblob_no_translate', 'sentiment_score_textblob_no_translate','polarity_textblob_no_translate' ]] = df_all['clean_comment'].apply(\n",
    "    lambda x: pd.Series(get_sentiment_label_and_score(x))\n",
    ")\n",
    "end_time = time.time()\n",
    "print(f\"Time for sentiment analysis with textblob of all comments with no translation: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8339df8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv('full_cleaned_textblob', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c087272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1538680 entries, 0 to 1538679\n",
      "Data columns (total 9 columns):\n",
      " #   Column                                 Non-Null Count    Dtype  \n",
      "---  ------                                 --------------    -----  \n",
      " 0   work                                   1538680 non-null  int64  \n",
      " 1   user                                   1538680 non-null  object \n",
      " 2   stars                                  1298896 non-null  float64\n",
      " 3   time                                   1538680 non-null  object \n",
      " 4   clean_comment                          1538680 non-null  object \n",
      " 5   language                               1538680 non-null  object \n",
      " 6   sentiment_label_textblob_no_translate  1538680 non-null  object \n",
      " 7   sentiment_score_textblob_no_translate  1538680 non-null  float64\n",
      " 8   polarity_textblob_no_translate         1538680 non-null  float64\n",
      "dtypes: float64(3), int64(1), object(5)\n",
      "memory usage: 105.7+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "textblob_df = pd.read_csv('full_cleaned_textblob')\n",
    "textblob_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fbc8883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          stars  \\\n",
      "stars                                  1.000000   \n",
      "sentiment_score_textblob_no_translate  0.199906   \n",
      "\n",
      "                                       sentiment_score_textblob_no_translate  \n",
      "stars                                                               0.199906  \n",
      "sentiment_score_textblob_no_translate                               1.000000  \n",
      "Pearson correlation between actual stars and Textblob-generated stars: 0.19990597731292578\n",
      "                                   stars  polarity_textblob_no_translate\n",
      "stars                           1.000000                        0.241048\n",
      "polarity_textblob_no_translate  0.241048                        1.000000\n",
      "Pearson correlation between actual stars and Textblob-generated stars: 0.24104792896728466\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation between 'stars' and 'sentiment_score_bert'\n",
    "correlation = textblob_df[['stars', 'sentiment_score_textblob_no_translate']].corr()\n",
    "\n",
    "# Print the correlation matrix\n",
    "print(correlation)\n",
    "\n",
    "# Alternatively, if you want just the Pearson correlation value between the two columns:\n",
    "pearson_corr = correlation.loc['stars', 'sentiment_score_textblob_no_translate']\n",
    "print(f\"Pearson correlation between actual stars and Textblob-generated stars: {pearson_corr}\")\n",
    "\n",
    "# Calculate the correlation between 'stars' and 'sentiment_score_bert'\n",
    "correlation = textblob_df[['stars', 'polarity_textblob_no_translate']].corr()\n",
    "\n",
    "# Print the correlation matrix\n",
    "print(correlation)\n",
    "\n",
    "# Alternatively, if you want just the Pearson correlation value between the two columns:\n",
    "pearson_corr = correlation.loc['stars', 'polarity_textblob_no_translate']\n",
    "print(f\"Pearson correlation between actual stars and Textblob-generated stars: {pearson_corr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc3969d",
   "metadata": {},
   "source": [
    "## Sentiment analysis with bert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "634ab61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['full_cleaned_part_1.csv',\n",
       " 'full_cleaned_part_2.csv',\n",
       " 'full_cleaned_part_3.csv',\n",
       " 'full_cleaned_part_4.csv',\n",
       " 'full_cleaned_part_5.csv']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the full_cleaned.csv\n",
    "df_all = pd.read_csv('full_cleaned.csv')   # full_cleaned.csv = no duplicate comments, all english + 5 other non english languages data\n",
    "\n",
    "# Determine the number of rows in each part\n",
    "total_rows = len(df_all)\n",
    "rows_per_part = total_rows // 5\n",
    "\n",
    "# Split the DataFrame into 5 equal parts and save each as a CSV\n",
    "output_paths = []\n",
    "for i in range(5):\n",
    "    start_idx = i * rows_per_part\n",
    "    end_idx = start_idx + rows_per_part if i < 4 else total_rows  # Ensure the last part takes the remainder\n",
    "    part_df = df_all.iloc[start_idx:end_idx]\n",
    "    part_file_path = f\"full_cleaned_part_{i + 1}.csv\"\n",
    "    part_df.to_csv(part_file_path, index=False)\n",
    "    output_paths.append(part_file_path)\n",
    "\n",
    "output_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4aaebdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       work              user  stars          time  \\\n",
      "0     73960  Elizabeth.Wong98    4.5  Mar 21, 2012   \n",
      "1     69413            rivkat    3.0  Sep 20, 2009   \n",
      "2   9523995      suz.haugland    4.0  Mar 12, 2011   \n",
      "3  11243828            CandyH    4.0  Feb 12, 2012   \n",
      "4   9071901          miyurose    2.0  Jul 12, 2010   \n",
      "\n",
      "                                       clean_comment language  \\\n",
      "0  every evening the brave queen of persia shahra...       en   \n",
      "1  its the  school year and edward zanni of hobok...       en   \n",
      "2  i became privy to this book when another autho...       en   \n",
      "3  this is a tremendous story of a freed woman an...       en   \n",
      "4  and with this book i am officially caught up w...       en   \n",
      "\n",
      "   sentiment_score_bert  \n",
      "0                     4  \n",
      "1                     3  \n",
      "2                     4  \n",
      "3                     4  \n",
      "4                     2  \n",
      "(1538680, 7)\n"
     ]
    }
   ],
   "source": [
    "mer_1 = pd.read_csv('full_cleaned_part_1.csv')\n",
    "mer_2 = pd.read_csv('full_cleaned_part_2.csv')\n",
    "mer_3 = pd.read_csv('full_cleaned_part_3.csv')\n",
    "mer_4 = pd.read_csv('full_cleaned_part_4.csv')\n",
    "mer_5 = pd.read_csv('full_cleaned_part_5.csv')\n",
    "\n",
    "\n",
    "# Concatenate the DataFrames along rows (axis=0)\n",
    "merged_df = pd.concat([mer_1, mer_2, mer_3, mer_4, mer_5], axis=0, ignore_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('Merged_Reviews_All_Parts.csv', index=False)\n",
    "\n",
    "# Check the result\n",
    "print(merged_df.head())  # Display the first few rows of the merged dataframe\n",
    "print(merged_df.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7e05666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "work                     446821\n",
       "user                      78055\n",
       "stars                        10\n",
       "time                       2920\n",
       "clean_comment           1538680\n",
       "language                      6\n",
       "sentiment_score_bert          5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.nunique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
